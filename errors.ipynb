{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurements uncertainties\n",
    "==========================\n",
    "\n",
    "In this chapter we describe how to treat and combine the statistical and\n",
    "systematic uncertainties associated to measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions\n",
    "-----------\n",
    "\n",
    "**Precision:** how reproducible is the measurement under identical\n",
    "conditions.\n",
    "\n",
    "**Accuracy:** how close the measured value is to the nominal/reference\n",
    "value.\n",
    "\n",
    "One can be very precise, but not accurate (always measuring exactly the\n",
    "same, but wrong value). More measurements may increase the precision,\n",
    "but not the accuracy.\n",
    "\n",
    "```{figure} ./images/ch3/precisionAccuracy.png\n",
    "---\n",
    "width: 400px\n",
    "align: center\n",
    "name: fig-precisionAccuracy\n",
    "---\n",
    "FIXME: Precision and acuracy. [wiki]\n",
    "```\n",
    "\n",
    "**(Intrinsic) Resolution:** the smallest change in a measured value that\n",
    "the instrument can detect. NB: many particle detector systems are based\n",
    "on internal statistical processes (like energy loss, shower development\n",
    "in calorimeters etc..), and thus their resolution comes from the\n",
    "addition of several sources which can are typically described by a\n",
    "\"Gaussian\" distribution.\n",
    "\n",
    "We will use the names resolution for instruments and sensitivity\n",
    "measurements.\n",
    "\n",
    "**Measurement range:** the difference between largest and smallest input\n",
    "value that an instrument is capable of measuring/reading\n",
    "\n",
    "**Dynamic range:** the ratio between measurement range and the\n",
    "resolution (quoted usually as log value \"decibel=dB\" in base-10)\n",
    "\n",
    "**Bandwidth:** the difference between the upper and lower frequencies\n",
    "(in electronics) that an instrument is capable of measuring. Or the\n",
    "maximal throughput for data transfer (computing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainties and the CLT\n",
    "-------------------------\n",
    "\n",
    "Any measurement we perform is affected by several uncertainties\n",
    "generated by several different sources. Let's say you measure your\n",
    "weight on a scale. The number indicated by the needle will be affected\n",
    "by several sources of uncertainties: parallax, rounding, your movements\n",
    "etc\\... That's the reason why when presenting a measurement we don't\n",
    "just give the central value $x$, but we $\\textit{must}$ quote its\n",
    "uncertainty $\\pm \\sigma_x$. This number is usually represented by a\n",
    "Gaussian standard deviation. The reason why we can use the Gaussian\n",
    "assumption as a way to present the uncertainty (i.e. why we implicitly\n",
    "make the assumption that the measurements are Gaussian distributed)\n",
    "comes from the central limit theorem (see [CLT](./probabilityDistributions.html#the-central-limit-theorem))\n",
    "A measurement affected by the effect of many independent additive\n",
    "effects will be \"approximately\" Gaussian distributed. \"Approximately\"\n",
    "means that the *core* of the distribution is well described by a\n",
    "Gaussian distribution, while the *tails* typically will show deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error propagation\n",
    "-----------------\n",
    "\n",
    "Typically the measurement of an observable is extracted from the\n",
    "combination of several different quantities measured directly. In this\n",
    "section we will analyse how the uncertainty on those quantities can be\n",
    "combined/propagated to the final measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function of one variable\n",
    "\n",
    "We start the discussion about error propagation from the most simple\n",
    "case. Let $f$ be a function of only one variable $x$. The basic idea is\n",
    "to see how much the function changes when the values of $x$ moves within\n",
    "its uncertainty. For this we make a Taylor expansion of $f$ around\n",
    "$x_{0}$ to the first order:\n",
    "\n",
    "$$\n",
    "f(x)\\approx f(x_0)+(x-x_0)\\left(\\frac{df}{dx}\\right)_{x=x_0}\n",
    "$$ \n",
    "\n",
    "Using $V(f)=<f^2>-<f>^2$ yields\n",
    "\n",
    "$$\n",
    "V(f)=\\sigma_f^2\\approx \\left(\\frac{df}{dx}\\right)^2\\sigma_x^2.\n",
    "$$ \n",
    "\n",
    "This approximation is only true if the uncertainties are small, i.e. the\n",
    "first derivative must not vary too much within the neighborhood of a few\n",
    "$\\sigma$. The derivative should be estimated at the true value of $x$\n",
    "and when that is unknown its measured value is used.\n",
    "\n",
    "```{margin}\n",
    "You can read the product/quotient formula as: the percentage of fraction error\n",
    "adds in quadrature (i.e. if $x\\pm3\\%$, $y\\pm4\\%$ then the uncertainty\n",
    "on $x\\cdot y$ and $x/y$ is $\\pm 5\\%$); same is true for the\n",
    "reciprocal, the percentage error on a quantity and its reciprocal are\n",
    "the same.\n",
    "``` \n",
    "Some examples of error propagation are shown in the following table:\n",
    "\n",
    "|      $z = f(x,y)$     |                                            Uncertainty                               |\n",
    "|  ---------------------|------------------------------------------------------------------------------------- |\n",
    "|      $z = x\\pm y$     |                            $\\sigma_z = \\sqrt{\\sigma_x^2 + \\sigma_y^2}$               |\n",
    "|     $z = x\\cdot k$    |                                   $\\sigma_z = k \\cdot \\sigma_x$                      |\n",
    "|   $z = x\\cdot y\\;\\;$  |$\\frac{\\sigma_z}{z} = \\sqrt{\\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2}$ |\n",
    "|      $z = x / y$       |$\\frac{\\sigma_z}{z} = \\sqrt{\\left(\\frac{\\sigma_x}{x}\\right)^2 + \\left(\\frac{\\sigma_y}{y}\\right)^2}$ |\n",
    "|       $z = x^n$        |                            $\\frac{\\sigma_z}{z} = n \\frac{\\sigma_x}{x}$              |\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.00+/-0.10\n",
      "y = 3.00+/-0.20\n",
      "x + y = 5.00+/-0.22\n",
      "x * 2 = 4.00+/-0.20\n",
      "x * y = 6.0+/-0.5\n",
      "x / y = 0.67+/-0.06\n",
      "x ** 2 = 4.0+/-0.4\n"
     ]
    }
   ],
   "source": [
    "import uncertainties\n",
    "import numpy as np\n",
    "\n",
    "x = uncertainties.ufloat(2.0, 0.1)\n",
    "print(f\"x = {x}\")\n",
    "y = uncertainties.ufloat(3.0, 0.2)\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "# sum\n",
    "print(f\"x + y = {x + y}\")\n",
    "\n",
    "# multiplication by a number\n",
    "print(f\"x * 2 = {x * 2}\")\n",
    "\n",
    "# product\n",
    "print(f\"x * y = {x * y}\")\n",
    "\n",
    "# division\n",
    "print(f\"x / y = {x / y}\")\n",
    "\n",
    "# power\n",
    "print(f\"x ** 2 = {x ** 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function of several variables\n",
    "\n",
    "In the case of a function $f(x,y)$ of two variables $x$ and $y$, we\n",
    "repeat the Taylor expansion to the first order:\n",
    "\n",
    "$$\n",
    "f(x,y)\\approx f(x_0,y_0)+\\left(\\frac{\\partial f}{\\partial x}\\right)_{x_0,y_0}\\cdot(x-x_0)+\\left(\\frac{\\partial f}{\\partial y}\\right)_{x_0,y_0}\\cdot(y-y_0)\n",
    "$$\n",
    "\n",
    "Again we assume that the uncertainties are small, which allows us to\n",
    "drop the higher-order terms of the Taylor expansion. We thus get the\n",
    "result: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V(f) &=&\\left(\\frac{\\partial f}{\\partial x}\\right)^2V(x)+\\left(\\frac{\\partial f}{\\partial y}\\right)^2V(y)+2\\frac{\\partial f}{\\partial x}\\frac{\\partial f}{\\partial y}\\cdot \\mbox{cov}(x,y)\\\\\n",
    "\\sigma_{f}^2&=&\\left(\\frac{\\partial f}{\\partial x}\\right)^2\\sigma_x^2+\\left(\\frac{\\partial f}{\\partial y}\\right)^2\\sigma_y^2+2\\frac{\\partial f}{\\partial x}\\frac{\\partial f}{\\partial y}\\cdot \\mbox{cov}(x,y)\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mbox{cov}(x,y) = \\left<(x-<x>)\\cdot (y-<y>)\\right>$ is the\n",
    "covariance, defined as:\n",
    "\n",
    "$$\n",
    "V_{ij} = \\mbox{cov}(x_{i},x_{j}) = \n",
    "\\left(\\begin{array}{cc}\n",
    "    \\sigma_x^2 & \\mbox{cov}(x,y) \\\\\n",
    "    \\mbox{cov}(x,y)   & \\sigma_y^2\n",
    "  \\end{array}\\right) =\n",
    "\\left(\\begin{array}{cc}\n",
    "    \\sigma_x^2 & \\rho\\sigma_x \\sigma_y \\\\\n",
    "    \\rho\\sigma_x \\sigma_y & \\sigma_y^2\n",
    "  \\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "where $\\rho$ is the correlation coefficient defined in Eq.{eq}`rho`.\n",
    "\n",
    "The covariance matrix is a *symmetric* $n \\times n$\n",
    "matrix, which can be generalized for a function $f$ of $n$ variables\n",
    "$x_1,x_2,\\ldots x_n$ as:\n",
    "\n",
    "$$\n",
    "\\sigma_f^2=\\sum_j\\left(\\frac{\\partial f}{\\partial x_j}\\right)^2\\cdot \\sigma^2_{x_j}+\\sum_{j}\\sum_{k\\ne j}\\left(\\frac{\\partial f}{\\partial x_j}\\right)\\left(\\frac{\\partial f}{\\partial x_k}\\right)\\cdot \\mbox{cov}(x_j,x_k)\n",
    "$$\n",
    "\n",
    "For continuous variables the diagonal elements $V_{ij}$ are the\n",
    "variances\n",
    "\n",
    "$$\n",
    "\\sigma_{x_i}^2=\\int (x_i-<x_i>)^2 f(x_1,\\ldots x_n)dx_1\\ldots dx_n\n",
    "$$\n",
    "\n",
    "and they are always positive. The off-diagonal elements can be positive\n",
    "or negative, and they represent the covariances:\n",
    "\n",
    "$$\n",
    "V_{ij}=\\int (x_i-<x_i>)(x_j-<x_j>) f(x_1,\\ldots x_n)dx_1\\ldots dx_n.\n",
    "$$\n",
    "\n",
    "```{admonition} Example:\n",
    ":class: tip\n",
    "Let $A = \\frac{F-B}{F+B}$ be the measured\n",
    "forward/backward-asymmetry of an angular distribution, where $F$ ($B$)\n",
    "is the forward (backward) hemisphere of a detector. Be $N = F+B$ the\n",
    "total number of measured events. If the uncertainties $\\sigma_{F}$ and\n",
    "$\\sigma_{B}$ for $F$ and $B$ are uncorrelated (this is the case if $N$\n",
    "is not fixed), we have\n",
    "\n",
    "$$\n",
    "\\sigma_A=\\frac{2FB}{N^2}\\sqrt{\\left(\\frac{\\sigma_F}{F}\\right)^2\n",
    "+\\left(\\frac{\\sigma_B}{B}\\right)^2}.\n",
    "$$ \n",
    "\n",
    "In the case of Poisson distributed events ($\\sigma_{F}^{2} = F$ and $\\sigma_{B}^{2}=B$) we\n",
    "have: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma_A&=&\\frac{2FB}{N^2}\\sqrt{\\frac{1}{F}\n",
    "+\\frac{1}{B}} \\\\\n",
    "\\sigma_A&=&\\frac{1-A^2}{2}\\sqrt{\\left(\\frac{1}{F}+\\frac{1}{B}\\right)}\\end{aligned}\n",
    "$$\n",
    "\n",
    "From that we can distinguish two limiting cases:\n",
    "\n",
    "-   $F\\sim B\\sim N/2$ and the asymmetry $A\\sim 0$:\n",
    "    Thus the uncertainty is $\\sigma_A\\sim \\frac{\\delta N}{N}$.\n",
    "\n",
    "-   $F\\gg B$ and hence $A\\sim +1$:\n",
    "    $\\sigma_A\\sim \\frac{2\\delta B}{N}$, i.e. the uncertainty is\n",
    "    dominated by the uncertainty of the smaller number of events.\n",
    "\n",
    "Alternatively we can also fix the total number of events $N$ and\n",
    "consider the events $F$ and $B$ as binomially distributed: let $p$ is\n",
    "the probability that a particle is registered in the forward hemisphere\n",
    "of the detector. From this it follows that:\n",
    "$\\sigma_F^2=\\sigma_B^2=Np(1-p)\\sim FB/N$. \n",
    "\n",
    "Because $F$ and $B$ are fully anti-correlated (which means that cov(F,B) = $- \\sigma^2_{F}$), \n",
    "it follows\n",
    "\n",
    "$$\n",
    "\\sigma_A^2=\\left(\\frac{\\partial A}{\\partial F}\\, \\, \\frac{\\partial A}{\\partial B} \\right)\\left(\\begin{array}{cc}\\sigma_F^2 & -\\sigma_F^2 \\\\\n",
    "-\\sigma_F^2 & \\sigma_F^2\n",
    "\\end{array}\\right)\n",
    "{\\frac{\\partial A}{\\partial F}\\choose \\frac{\\partial A}{\\partial B}}.\n",
    "$$\n",
    "\n",
    "Finally with $\\partial A/ \\partial F= - \\partial A/ \\partial B=1/N$ we\n",
    "get: \n",
    "\n",
    "$$\n",
    "\\sigma_A=\\frac{2}{N}\\sqrt{\\frac{FB}{N}}\n",
    "$$\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.00+/-0.10\n",
      "y = 3.00+/-0.20\n",
      "f(x, y) = 8.0+/-0.4\n",
      "covariance matrix:\n",
      "[[0.01 0.   0.01]\n",
      " [0.   0.04 0.08]\n",
      " [0.01 0.08 0.17]]\n",
      "correlation matrix:\n",
      "[[1.         0.         0.24253563]\n",
      " [0.         1.         0.9701425 ]\n",
      " [0.24253563 0.9701425  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "x = uncertainties.ufloat(2.0, 0.1)\n",
    "print(f\"x = {x}\")\n",
    "y = uncertainties.ufloat(3.0, 0.2)\n",
    "print(f\"y = {y}\")\n",
    "f = x + 2 * y\n",
    "print(f\"f(x, y) = {f}\")\n",
    "\n",
    "# covariance matrix\n",
    "cov = uncertainties.covariance_matrix([x, y, f])\n",
    "print(f\"covariance matrix:\\n{np.array(cov)}\")\n",
    "\n",
    "# correlation matrix\n",
    "corr = uncertainties.correlation_matrix([x, y, f])\n",
    "print(f\"correlation matrix:\\n{np.array(corr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several functions of several variables\n",
    "\n",
    "Finally we look at the most general case, in which we have a set of\n",
    "random variables ${x} = (x_{1}, \\ldots, x_{n})$ with expectation\n",
    "values ${\\mu}= (\\mu_{1}, \\ldots, \\mu_{n})$ belonging to the set of\n",
    "probability density functions ${F}({x})={f_1,f_2,\\ldots,f_n}$.\n",
    "The covariance matrix $U_{kl}$ is then given by:\n",
    "\n",
    "$$\n",
    "U_{kl}=cov(f_k,f_l)= \\sum_{i,j}\\left(\\frac{\\partial f_k}{\\partial x_i}\\frac{\\partial f_l}{\\partial x_j}\\right)_{\\mbox{x=${\\mu}$}} cov(x_i,x_j).\n",
    "$$\n",
    "\n",
    "This can be written in a shortened way as $U = A\\, V\\, A^{T}$ where the\n",
    "matrix $A$ of the derivatives is given by\n",
    "\n",
    "$$\n",
    "A_{ij}=\\left(\\frac{\\partial f_i}{\\partial x_j}\\right)_{\\mbox{ x=$\\mu$}}\n",
    "$$\n",
    "\n",
    "and $A^{T}$ is its transpose. The matrices $U=cov(f_{i},f_{j})$ and\n",
    "$V=cov(x_{i},x_{j})$ contain the covariance for $f$ and $x$. Both are\n",
    "symmetric with dimension $n \\times n$.\n",
    "\n",
    "```{admonition} Example:\n",
    ":class: tip\n",
    "Transformation to polar coordinates in 2D. Assume we have\n",
    "measured a point in cartesian coordinates $x$ and $y$ with the\n",
    "uncertainties $\\sigma_{x}$ and $\\sigma_{y}$. The measurements in $x$ and\n",
    "$y$ shall be independent such that we can write $V_{11}=\\sigma_{x}^{2}$,\n",
    "$V_{22}=\\sigma_{y}^{2}$ and $V_{i \\ne j}=0$. Now we want to get the\n",
    "covariance matrix in polar coordinates. The transformation equations are\n",
    "$f_1:\\,r^2=x^2+y^2$ and $f_2:\\, \\theta=arctan (y/x)$. It follows for\n",
    "$A=\\partial f_i/\\partial x_i$:\n",
    "\n",
    "$$\n",
    "A = \\left( \\begin{array}{cc}\n",
    " \\frac{\\partial r}{\\partial x} & \\frac{\\partial r}{\\partial y}  \\\\\n",
    " \\frac{\\partial \\theta}{\\partial x}& \\frac{\\partial \\theta}{\\partial y} \\end{array} \\right)\n",
    " =\\left( \\begin{array}{cc}\n",
    " \\frac{x}{r} & \\frac{y}{r}  \\\\\n",
    " \\frac{-y}{r^2}& \\frac{x}{r^2} \\end{array} \\right)\n",
    "$$ \n",
    "\n",
    "And with this we can compute $U=A\\,V\\,A^{T}$: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "U &=& \\left( \\begin{array}{cc}\n",
    " \\frac{x}{r} & \\frac{y}{r}  \\\\\n",
    " \\frac{-y}{r^2}& \\frac{x}{r^2} \\end{array} \\right)\n",
    " \\cdot \\left( \\begin{array}{cc}\n",
    " \\sigma_x^2 & 0  \\\\\n",
    " 0& \\sigma_y^2 \\end{array} \\right) \\cdot\n",
    "\\left( \\begin{array}{cc}\n",
    " \\frac{x}{r} & \\frac{-y}{r^2}  \\\\\n",
    " \\frac{y}{r}& \\frac{x}{r^2} \\end{array} \\right)\\\\\n",
    "U&=&\\left( \\begin{array}{cc}\n",
    " \\frac{1}{r^2}(x^2\\sigma^2_x+y^2\\sigma^2_y) & \\frac{xy}{r^3}(-\\sigma_x^2+\\sigma_y^2)  \\\\\n",
    " \\frac{xy}{r^3}(-\\sigma_x^2+\\sigma_y^2)& \\frac{1}{r^4}(y^2\\sigma_x^2+x^2\\sigma_y^2) \\end{array} \\right)\n",
    "=\\left( \\begin{array}{cc}\n",
    "\\sigma_r^2 & \\sigma^2_{r\\theta} \\\\\n",
    "\\sigma^2_{r\\theta} & \\sigma_{\\theta}^2\n",
    "\\end{array} \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty on efficiencies\n",
    "---------------------------\n",
    "\n",
    "Suppose you are performing a \"counting experiment\" and you decide to\n",
    "accept events only if they pass a set of selection criteria (e.g. $p_T>$\n",
    "20 GeV; $|\\eta|<2.5$). Call $N_0$ the total number of events and $N_p$\n",
    "the subset passing the selection. The efficiency of the selection is:\n",
    "\n",
    "$$\n",
    "\\epsilon = \\frac{N_p}{N_0}\n",
    "$$ \n",
    "\n",
    "You cannot apply a straightforward error\n",
    "propagation on uncorrelated Poisson uncertainties because $N_p$ and\n",
    "$N_0$ are correlated.\n",
    "\n",
    "The correct way to compute the uncertainty is to look at the equivalent\n",
    "binomial problem with total number of events $N_0$ and probability\n",
    "$\\epsilon$ to pass:\n",
    "\n",
    "$$\n",
    "\\left( \\Delta \\epsilon \\right)^2 = \\frac{\\epsilon(1-\\epsilon)}{N_0}\n",
    "$$\n",
    "\n",
    "Another way to get to the same result is to work with the uncorrelated\n",
    "variables pass $N_p$ and fail $N_f$, such that the total number $N_0$ is\n",
    "not a fixed number: $$\\epsilon = \\frac{N_p}{N_p + N_f}$$ and then apply\n",
    "error propagation: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left( \\Delta \\epsilon \\right)^2 &=& \\left( \\frac{\\partial \\epsilon}{\\partial N_p}\\right)^2(\\Delta N_p)^2 + \\left(  \\frac{\\partial \\epsilon}{\\partial N_f}\\right)^2 (\\Delta N_f)^2 \\\\\n",
    " &=& \\left( \\frac{N_f}{N_0^2}\\right)^2(\\Delta N_p)^2 + \\left(-\\frac{N_p}{N_0^2}\\right)^2 (\\Delta N_f)^2 \\\\\n",
    " &=& \\frac{(1-\\epsilon)^2N_p + \\epsilon^2 N_f}{N_0}\\\\\n",
    " &=& \\frac{\\epsilon(1-\\epsilon)}{N_0}\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty on the mean\n",
    "-----------------------\n",
    "\n",
    "Suppose we measure $n$ times the quantity $x$. The measured mean value\n",
    "of $x$ is $\\bar{x} = \\sum_i x_i / n$. As all the single measurements,\n",
    "also the mean will be affected by statistical fluctuations. The\n",
    "difference between the measured mean $\\bar{x}$ and $\\mu$ (the\n",
    "true-unknown value of the quantity) is described by a Gaussian\n",
    "distribution (because of the CLT) with variance\n",
    "$V(\\bar{x}) = \\sigma^2 / n$. For $n\\to \\infty$ (if the measurement is\n",
    "not biased, see [properties of estimators](likelihood.html#properties-of-the-estimators)\n",
    "it will converge to the \"true\" value:\n",
    "$\\langle \\bar{x} \\rangle = \\mu$. The variance of $\\bar{x}$ is the\n",
    "variance of $x$ divided by $n$: $V(\\bar{x})= \\sigma^2 /n$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  Var(\\bar{x}) & = &  \\langle (\\bar{x} -\\mu )^2 \\rangle \\\\\n",
    "               & = &  \\langle \\left( \\frac{1}{n} \\sum_i x_i - \\mu  \\right) ^2\\rangle\\\\\n",
    "               & = &  \\frac{1}{n^2} n \\langle x^2 \\rangle + \\frac{n(n-1)}{n^2} \\langle x_i x_j\\rangle_{i\\neq j} - 2\\mu\\langle \\bar{x} \\rangle + \\mu^2\\\\\n",
    "               & = &  \\frac{\\langle x^2 \\rangle}{n} + \\frac{n-1}{n} \\mu^2 -\\mu^2\\\\\n",
    "               & = &  \\frac{\\langle x^2 -\\mu^2\\rangle}{n} = \\frac{\\sigma^2}{n} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The *standard deviation of the mean* falls like $1/\\sqrt{n}$. To improve\n",
    "the resolution of your measurement by a factor of 2 you need to get 4\n",
    "times more measurements (*slang:* 4 times more statistics).\n",
    "\n",
    "```{admonition} Example:\n",
    ":class: tip\n",
    "Take a photo-detector with an energy resolution of 50 keV.\n",
    "If a mono-energetic photon (coming e.g. from a certain nuclear decay) is\n",
    "registered, its energy is only known to a precision of 50 keV. If 100\n",
    "(mono-energetic) photons are measured (all coming from the same nuclear\n",
    "decay), then the uncertainty of the mean energy is only\n",
    "$50/\\sqrt{100} = 5$ keV. For a resolution of 1 keV we need 2500 events.\n",
    "So, to double the precision, you need four times more photons.\n",
    "```\n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted mean\n",
    "-------------\n",
    "\n",
    "Suppose we want to compute the average of a set of measurements $x_{i}$\n",
    "with different uncertainties $\\sigma_{i}$. Intuitively the measurements\n",
    "with large uncertainties will \"matter\" less than measurements with small\n",
    "uncertainties.\n",
    "\n",
    "```{admonition} Example:\n",
    ":class: tip\n",
    "You have two measurements of $x$: $10\\pm0.1$ and $8\\pm 5$.\n",
    "In this case the second measurement will have basically no weight in\n",
    "your knowledge about $x$.\n",
    "```\n",
    "\n",
    "The correct way to obtain the mean in this case is to take into account\n",
    "explicitly the uncertainty of the measurements: \n",
    "\n",
    "```{math}\n",
    ":label: wmean\n",
    "\\begin{aligned}\n",
    "\\bar{x}&=&\\frac{\\sum x_i/\\sigma_i^2}{\\sum 1/\\sigma_i^2} \\\\\n",
    "\\sigma_{\\bar{x}}^2&=&\\frac{1}{\\sum 1/\\sigma_i^2}\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "In this\n",
    "case the individual results are weighted such that the values with small\n",
    "uncertainties contribute more to the average.\n",
    "Some comments:\n",
    "\n",
    "-   The weighted mean collapses to the arithmetic mean when fixing all\n",
    "    the uncertainty's to be equal\n",
    "\n",
    "-   \"Few measurements with small uncertainties are better than many\n",
    "    measurements with large uncertainties\". Let the uncertainty of a\n",
    "    first set of $n_1$ measurements of the quantity $x$ be $\\sigma_{1}$.\n",
    "    The uncertainty on the mean is\n",
    "    $\\sigma_{\\bar{x}} = \\sigma_1/\\sqrt{n_1}$. If we have a second set of\n",
    "    $n_2$ measurements with uncertainty $\\sigma_{2}$ and\n",
    "    $\\sigma_{2} > \\sigma_{1}$ then to get to the same precision you need\n",
    "    to collect more data as:\n",
    "    $n_{2} = n_{1} \\left( \\frac{\\sigma_{2}}{\\sigma_{1}} \\right) ^{2}$\n",
    "\n",
    "-   Care must be taken if the individual results and their uncertainty's\n",
    "    deviate too much from each other. Consider the following example: An\n",
    "    experiment measures in one hour $100 \\pm 10$ events, and another\n",
    "    experiment measures in one hour only $1 \\pm 1$ events. The\n",
    "    Eq.{eq}`wmean` would then tell us that we have $2 \\pm 1$\n",
    "    events. But the (unweighted) mean would give $50.5 \\pm 5$. In this\n",
    "    case instead of blindly quote the mean or the weighted mean you\n",
    "    should go back and understand *why* you get such different outcomes\n",
    "    (it might be a problem of some parameters of the data taking, some\n",
    "    faulty equipment, some trivial mistake etc\\...). In case you can't\n",
    "    find any reason for that, it would be wise to give the full\n",
    "    information at hand and preset both results\n",
    "\n",
    "```{admonition} Example:\n",
    ":class: tip\n",
    "FIXME REFS: Compute the best estimate of the Higgs mass from the ATLAS (\n",
    "$m_H= 125.36 \\pm 0.41$ GeV) [@ATLASmassH] and CMS\n",
    "($m_H = 125.02 \\pm 0.30$ GeV) [@CMSmassH]. Applying the formula for the\n",
    "weighted average we get: $m_H = 125.14 \\pm 0.24$ GeV. Compare it with\n",
    "the official LHC combination.\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A closer look at the error matrix\n",
    "---------------------------------\n",
    "\n",
    "We have encountered in the previous sections the error matrix (also\n",
    "called covariance matrix). Here we will take a closer look at it,\n",
    "focusing on the importance of the off-diagonal terms describing the\n",
    "correlations.\\\n",
    "Let's start from the case of a 2D probability density function built\n",
    "from two *uncorrelated* Gaussian distributions in $x$ and $y$. The two\n",
    "p.d.f.'s are: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(x) &=& \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sigma_x} e^{-\\frac{1}{2}\\frac{x^2}{\\sigma_x^2}}\\\\\n",
    "P(y) &=& \\frac{1}{\\sqrt{2\\pi}} \\frac{1}{\\sigma_y} e^{-\\frac{1}{2}\\frac{y^2}{\\sigma_y^2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "(for simplicity we take the two distributions to be centred at 0) and\n",
    "the combined 2D uncorrelated distribution is just the product of the\n",
    "two:\n",
    "\n",
    "$$\n",
    "P(x,y) = \\frac{1}{2\\pi} \\frac{1}{\\sigma_x\\sigma_y} e^{-\\frac{1}{2} \\left( \\frac{x^2}{\\sigma_x^2} + \\frac{y^2}{\\sigma_y^2}\\right)}\n",
    "$$\n",
    "\n",
    "In one dimension the Gaussian probability is reduced by $1/\\sqrt{e}$\n",
    "when moving away from the maximum by 1$\\sigma$. In 2D this point becomes\n",
    "a curve and in this particular example an ellipse with equation:\n",
    "$$\\frac{x^2}{\\sigma_x^2} +\\frac{y^2}{\\sigma_y^2} = 1$$ We can rewrite\n",
    "the same equation in matrix form (in the case of no correlation is an\n",
    "overkill but this notation will become useful in the following):\n",
    "\n",
    "$$\n",
    "\\left(x,y \\right)\n",
    "\\left( \\begin{array}{cc}\n",
    "    \\frac{1}{\\sigma_x^2} & 0 \\\\\n",
    "    0 & \\frac{1}{\\sigma_y^2}  \\\\\n",
    "  \\end{array} \\right)\n",
    "\\left( \\begin{array}{c}\n",
    "  x\\\\\n",
    "  y\\\\\n",
    "\\end{array} \\right) = 1\n",
    "$$ \n",
    "\n",
    "The matrix in the previous equation is called\n",
    "the *inverse of the error matrix* and its inverse is called **error matrix for $x$ and $y$**: \n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{cc}\n",
    "    \\sigma_x^2 & 0 \\\\\n",
    "    0 & \\sigma_y^2  \\\\\n",
    "  \\end{array} \n",
    "  \\right)\n",
    "$$ \n",
    "\n",
    "The general element of the error(covariance)\n",
    "matrix for $n$ variables $x_1,\\ldots,x_n$ is given by:\n",
    "\n",
    "$$\n",
    "\\langle (x_i-\\bar{x_i})(x_j-\\bar{x_j}) \\rangle.\n",
    "$$\n",
    "\n",
    "The notation above allows to treat in a simple way the case of\n",
    "*correlated variables*.\n",
    "\n",
    "Take the previous uncorrelated case and rotate the $(x,y)$ axes as :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x' &=& x\\cos\\theta - y\\sin\\theta\\\\\n",
    "y' &=& x\\sin\\theta + y\\cos\\theta\\end{aligned}\n",
    "$$ \n",
    "\n",
    "\n",
    "Let's use a numerical example: be $\\sigma_x = 1/4$ and $\\sigma_y = 1/2$ (see {numref}`fig-errorEllipse`). An [interactive version](interactive-nbs/ErrorMatrix.ipynb) of it is also available.\n",
    "\n",
    "```{figure} ./images/ch3/errorEllipse.png\n",
    "---\n",
    "width: 400px\n",
    "align: center\n",
    "name: fig-errorEllipse\n",
    "---\n",
    "Interpretation of the uncertainty for two variables: the error\n",
    "ellipse.\n",
    "```\n",
    "\n",
    "Then the uncorrelated case reads: \n",
    "\n",
    "$$\n",
    "16 x^2 + 4 y^2 =1.\n",
    "$$\n",
    "\n",
    "Applying the rotation (i.e. correlating the two measurements (see\n",
    "{numref}`fig-errorEllipse`): \n",
    "\n",
    "$$\n",
    "\\left( x~y \\right)'\n",
    "\\left( \\begin{array}{cc}\n",
    "    \\cos\\theta   & \\sin\\theta \\\\\n",
    "    -\\sin \\theta & \\cos \\theta  \\\\\n",
    "  \\end{array} \\right)\n",
    "\\left( \\begin{array}{cc}\n",
    "    1/\\sigma_x^2 & 0 \\\\\n",
    "    0 & 1/\\sigma_y^2  \\\\\n",
    "  \\end{array} \\right)\n",
    "\\left( \\begin{array}{cc}\n",
    "    \\cos\\theta   & -\\sin\\theta \\\\\n",
    "    \\sin \\theta & \\cos \\theta  \\\\\n",
    "  \\end{array} \\right)\n",
    "\\left( \\begin{array}{c}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "  \\end{array} \\right)'\n",
    "  \n",
    "$$ \n",
    "\n",
    "we get \n",
    "\n",
    "$$\n",
    "\n",
    "\\label{eq:ellipse}\n",
    "\\left( x~y \\right)'\n",
    "\\left( \\begin{array}{cc}\n",
    "    13 &  3\\sqrt{3} \\\\\n",
    "    3\\sqrt{3} &  7 \\\\\n",
    "  \\end{array} \\right)\n",
    "\\left( \\begin{array}{c}\n",
    "    x \\\\\n",
    "    y \\\\\n",
    "  \\end{array} \\right)'.\n",
    "$$ \n",
    "\n",
    "The matrix in the centre is the \"inverse error\n",
    "matrix\" and its inverse is the \"error matrix\": \n",
    "\n",
    "$$\n",
    "\\frac{1}{64}\n",
    "\\left( \\begin{array}{cc}\n",
    "    7 &  -3\\sqrt{3} \\\\\n",
    "    -3\\sqrt{3} &  13 \\\\\n",
    "  \\end{array} \\right)\n",
    "$$ \n",
    "\n",
    "Given the error matrix is trivial to extract\n",
    "uncertainties on the variables and their correlation coefficients:\n",
    "\n",
    "-   the uncertainty on $x'$ is given by intersection of the rectangle\n",
    "    inscribing the ellipse with the x-axis: $\\sigma_{x'}^2 = 7/64$ the\n",
    "    square root of the first diagonal element of the error matrix\n",
    "\n",
    "-   the uncertainty on $y'$ is given by intersection of the rectangle\n",
    "    inscribing the ellipse with the y-axis: $\\sigma_{y'}^2 = 13/64$ the\n",
    "    square root of the second diagonal element of the error matrix\n",
    "\n",
    "-   the intersection of the ellipse with the x-axis is\n",
    "    $\\sqrt{1/13} = 0.277$ the inverse of the square root of the first\n",
    "    diagonal element of the inverse error matrix\n",
    "\n",
    "-   the intersection of the ellipse with the y-axis is\n",
    "    $\\sqrt{1/7} = 0.378$ the inverse of the square root of the second\n",
    "    diagonal element of the inverse error matrix\n",
    "\n",
    "-   the off-diagonal elements of the error-matrix are\n",
    "    $\\rho \\sigma_{x'} \\sigma_{y'}$; knowing $\\sigma_{x'}$ and\n",
    "    $\\sigma_{y'}$ from the diagonal elements we obtain a correlation\n",
    "    coefficient $\\rho = 0.54$.\n",
    "\n",
    "-   the semi-axes of the ellipse are the square roots of the eigenvalues\n",
    "    of the error matrix (here we know the diagonalized matrix, i.e.\n",
    "    before rotation, and we can just read them off: 0.25, 0.5)\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical vs. Systematic Uncertainties\n",
    "----------------------------------------\n",
    "\n",
    "When repeating measurements (for example to reduce the uncertainty by\n",
    "averaging over many results), the usual assumption is that the\n",
    "experiments can be repeated under identical conditions, being\n",
    "independent of each other and thus giving identical, independent\n",
    "results. Unfortunately, this *ideal world* does not exist. Repeated\n",
    "measurements will give slightly different results, due to diverse\n",
    "sources such as changing experimental conditions (mostly unknown),\n",
    "imprecise measurement (resolution), thermal or quantum fluctuations and\n",
    "others. The differences in the results are \"randomly\" varying, giving\n",
    "the so-called *statistical uncertainty*. For these kind of\n",
    "uncertainties, as in previous section, repeating the measurement\n",
    "increases the precision.\n",
    "\n",
    "A different kind of uncertainty is represented by the *systematic\n",
    "uncertainty*:\n",
    "\n",
    "-   **Systematic effect**= background, selection bias, efficiencies,\n",
    "    energy resolutions, angular resolution, theory\n",
    "    renormalizarion/factorization scales, etc...\n",
    "\n",
    "-   **Systematic uncertainty** = the uncertainty in estimating a\n",
    "    systematic effect\n",
    "\n",
    "-   **Systematic mistake** = result of negleting such effects\n",
    "\n",
    "Systematic uncertainties are usually independent from the statistical\n",
    "uncertainties. It is therefore important to always quote both\n",
    "uncertainties separately in the results:\n",
    "\n",
    "$$\n",
    "x = 10.2 \\pm 0.2 \\text{ (stat)} \\pm 0.3 \\text{ (syst)} [units]%  \\pm 0.3 \\text{ (theory)} [units].\n",
    "$$\n",
    "\n",
    "```{margin}\n",
    "Some systematic uncertainties do get reduced with larger data\n",
    "samples. Take the case of a systematics uncertainty associated to a\n",
    "calibration. If the calibration is performed on a sample of\n",
    "available data, the larger the calibration sample the smaller will\n",
    "be the uncertainty.\n",
    "```\n",
    "The systematic uncertainty is a statement made by the experimenters\n",
    "about their understanding of their own equipment, and in general it will\n",
    "not decrease with larger data samples (like the statistical\n",
    "uncertainty). An interesting situation is reached when the\n",
    "systematic uncertainty is larger than the statistical one. In this case\n",
    "the precision of the result will not be improved by taking more data; it\n",
    "will only improve by better understanding the experimental setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "Work with systematic uncertainties\n",
    "----------------------------------\n",
    "\n",
    "Once the systematic uncertainties are singled out, they can be treated\n",
    "with the same covariance matrices techniques developed above for the\n",
    "statistical uncertainties.\\\n",
    "Suppose you have two measurements $x_1$ and $x_2$ with statistical\n",
    "uncertainties $\\sigma_1$ and $\\sigma_2$ respectively and a common\n",
    "systematic uncertainty $S$. Putting together the components in a matrix\n",
    "we get: \n",
    "\n",
    "$$\n",
    "V_{i,j}^{tot} = \\left( \\begin{array}{cc}\n",
    "\\sigma_1^2+S^2 & S^2  \\\\\n",
    " S^2& \\sigma_2^2+S^2\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "If, instead of a constant systematic uncertainty, the uncertainty is\n",
    "given as a percentage $T= \\epsilon x_{i}$ (e.g. $\\epsilon = 0.01$ for a\n",
    "1%), then the covariance matrix is:\n",
    "\n",
    "$$\n",
    "V_{i,j}^{tot} = \\left( \\begin{array}{cc}\n",
    " \\sigma_1^2+\\epsilon^2 x_1^2 & \\epsilon^2x_1x_2  \\\\\n",
    " \\epsilon^2x_1x_2 & \\sigma^2+\\epsilon^2x_2^2 \\end{array} \\right)\n",
    " $$\n",
    " \n",
    " ```{admonition} Example:\n",
    ":class: tip\n",
    "Consider two variables $x$ and $y$ with two sources of\n",
    "uncertainties: a statistical ($s_{x}, s_{y}$) with *no* correlation and\n",
    "a systematic ($c_{x}, c_{y}$) with *full* correlation (e.g. luminosity):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x &=& x_{0} \\pm s_{x} \\text{ (stat)} \\pm c_{x} \\text{ (syst)} \\\\\n",
    "y &=& y_{0} \\pm s_{y} \\text{ (stat)} \\pm c_{y} \\text{ (syst)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Because the uncertainties are already separated into a correlated and\n",
    "uncorrelated category, they can be summed up in quadrature at the matrix\n",
    "level, yielding: \n",
    "\n",
    "$$\n",
    "V_{ij}^{tot} = \\left( \\begin{array}{cc}\n",
    "s_{x}^{2} & 0 \\\\\n",
    "0 & s_{y}^{2} \\end{array} \\right) + \\left( \\begin{array}{cc}\n",
    "c_{x}^{2} & c_{xy} \\\\\n",
    "c_{yx} & c_{y}^{2} \\end{array} \\right) = \\left( \\begin{array}{cc}\n",
    "\\sigma_{x}^{2} & \\rho \\sigma_{x} \\sigma_{y} \\\\\n",
    "\\rho \\sigma_{x} \\sigma_{y} & \\sigma_{y}^{2} \\end{array} \n",
    "\\right),\n",
    "$$ \n",
    "\n",
    "where\n",
    "$\\rho$ is the correlation coefficient\n",
    "$\\rho = \\frac{c_{xy}}{\\sigma_{x} \\sigma_{y}}$ and\n",
    "$\\sigma_{i}^{2} = s_{i}^{2} + c_{i}^{2}$ is the sum of the squared\n",
    "individual uncertainties for $x$ and $y$, respectively.\n",
    "```\n",
    "\n",
    "```{admonition} Example:\n",
    ":class: tip\n",
    "Take three variables $x_{1}, x_{2}, x_{3}$ with statistical\n",
    "uncertainties $\\sigma_{1},\\sigma_{2},\\sigma_{3}$, a common systematic\n",
    "uncertainty $S$ and a second systematic uncertainty $T$ shared by only\n",
    "$x_1$ and $x_2$. In this case the covariance matrix reads:\n",
    "\n",
    "$$\n",
    "V_{i,j}^{tot} = \\left( \\begin{array}{ccc}\n",
    " \\sigma_1^2+S^2+T^2 & S^2+T^2  & S^2 \\\\\n",
    " S^2+T^2 & \\sigma_2^2+S^2+T^2 & S^2 \\\\\n",
    "S^2 & S^2 & \\sigma_3^2+S^2\n",
    " \\end{array} \\right)\n",
    "$$\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Systematic Uncertainties\n",
    "-----------------------------------\n",
    "\n",
    "To deal with systematic uncertainties one has to distinguish between\n",
    "*known* and *unknown* (or *unsuspected*) sources of uncertainties.\n",
    "\n",
    "\"Known\" sources can be:\n",
    "\n",
    "-   uncertainties on factors in the analysis: calibration, efficiencies,\n",
    "    corrections, etc\\...\n",
    "\n",
    "-   theoretical uncertainties on branching ratios, masses, fragmentation\n",
    "    etc\\...\n",
    "\n",
    "To evaluate the impact of systematic uncertainties from known sources\n",
    "$s_{i}$ on a correction factor $F$, there are several possibilities.\n",
    "Either one can take several (the more the better) typical assumptions\n",
    "for $s_{i}$ and repeat the calculation of $F$ and then calculate the\n",
    "standard deviation of $F$. Or an experimental parameter (for example the\n",
    "energy resolution) can be varied up and down by one sigma and check the\n",
    "change in the variable. Or again another possibility is to take two\n",
    "extreme assumptions as values for the source $s_{i}$ and argue that the\n",
    "true value has to be in between them and use the difference divided by\n",
    "$\\sqrt{12}$. The factor $\\sqrt{12}$ is due to the standard deviation of\n",
    "the uniform distribution, which can be used to model the total ignorance\n",
    "about the parameter value.\n",
    "\n",
    "Uncertainties from \"unsuspected\" sources can be studied by repeating the\n",
    "analysis in different ways such as:\n",
    "\n",
    "-   vary the range of data used for extraction of the result\n",
    "\n",
    "-   use only a subset of the data (e.g. split the data into two\n",
    "    categories)\n",
    "\n",
    "-   change cuts, binning, borders of the histogram.\n",
    "\n",
    "-   change the parameterization or the fit technique\n",
    "\n",
    "Finding trends as a result of the above checks usually points to an\n",
    "\"unsuspected\" systematic effect.\\\n",
    "\\\n",
    "However you *should not* go through the previous list blindly and sum up\n",
    "in quadrature all resulting deviations. This will simply increase the\n",
    "systematic uncertainty the more effects the experimenters will conceive!\n",
    "It is wrong to state that \"the more careful you are the bigger should\n",
    "your systematic uncertainty be\". Remember that out of 20 checks one is\n",
    "expected to be off more than $2\\sigma$ and every third is off by\n",
    "$1\\sigma$ or more. If no systematic effect is expected a priori, and if\n",
    "the deviation from the expected result is not significant, no additional\n",
    "systematic uncertainty must be added. On the other hand, if you do see a\n",
    "deviation, try to understand where it comes from and eventually fix it.\n",
    "Only as a last resort include a discrepancy in systematic uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many digits?\n",
    "----------------\n",
    "\n",
    "We report here the recommendation from the PDG on how to round the\n",
    "numbers representing your results. The basic rule states that if the\n",
    "three highest order digits of the uncertainty lie between 100 and 354,\n",
    "we round to two significant digits. If they lie between 355 and 949, we\n",
    "round to one significant digit. Finally, if they lie between 950 and\n",
    "999, we round up to 1000 and keep two significant digits. In all cases,\n",
    "the central value is given with a precision that matches that of the\n",
    "uncertainty. So, for example, the result (coming from an average) 0.827\n",
    "$\\pm$ 0.119 would appear as 0.83 $\\pm$ 0.12, while 0.827 $\\pm$ 0.367\n",
    "would turn into 0.8 $\\pm$ 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------\n",
    "\n",
    "L. Lyons, \"Statistics for nuclear and particle physics\". Ch. 1 and Ch. 3\n",
    "\n",
    "R. Barlow, \" A guide to the use of statistical methods in the physical sciences\". Ch. 4\n",
    "\n",
    "J.R. Taylor [@Taylor], \"Introduction to error analysis\"\n",
    "\n",
    "R. Barlow [@systBarlow], \"Systematic Errors: facts and fictions\", https://arxiv.org/abs/hep-ex/0207026\n",
    "\n",
    "PDG, Introduction: On rounding conventions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

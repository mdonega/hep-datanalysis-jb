{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde1a151-d6ff-4b41-995c-cb5d50ba23ed",
   "metadata": {},
   "source": [
    "# Interactive Example - Upper Limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc9573-7c1e-4fdd-a3ea-8ed2feccccff",
   "metadata": {},
   "source": [
    "In this example we will generate a toy dataset with a small gaussian signal over an exponential background and use it to compute an expected and observed **upper limit** on the signal fraction. These operations are performed in the widgets in the last cell, which allows to tune the following parameters:\n",
    "- ```n_sig``` : number of signal events in the toy dataset\n",
    "- ```n_bkg```: number of background events in the toy dataset\n",
    "- ```likelihood```: type of likelihood to use, i.e. unbinned or binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b885f-9475-4ed0-ba60-0384d78ba7fa",
   "metadata": {},
   "source": [
    "In what follows we summarize the procedure developed in ```generate_compute_plot``` to compute upper limits for observed and expected data. This will be useful to understand the information displayed in the so-called \"brazilian bands\" plot.\n",
    "\n",
    "1. First of all, the toy dataset that simulates our observation is produced.\n",
    "2. Using the **profile likelihood ratio**\n",
    "\n",
    "$$\\lambda(\\mu) = \\frac{L(\\mu,\\hat{\\hat{\\theta}})}{L(\\hat{\\mu},\\hat{\\theta})}$$\n",
    "\n",
    "and the **test statistics**\n",
    "\n",
    "$$q_\\mu = \\left\\{\n",
    "            \\begin{array}{rll}\n",
    "                -2 \\ln \\lambda(\\mu) & \\mbox{if} & \\hat{\\mu} \\le \\mu \\\\\n",
    "                0                 & \\mbox{if} & \\hat{\\mu} > \\mu \n",
    "            \\end{array}\\right.$$\n",
    "we first define an array of test values ```pois_null``` for our POI (the signal fraction) and compute $CL_{s+b}$. Note that $CL_{s+b}$ is obtained using $p_\\mu = 1-F(q_\\mu|\\mu') = 1 - \\Phi(\\sqrt{q_\\mu})$.\n",
    "\n",
    "3. Generate an Asimov dataset.\n",
    "4. Compute $CL_{b}$ and $CL_s$ for each value of the POI we are testing.\n",
    "5. Compute the median, $1 \\sigma$ and $2 \\sigma$ expected $CL_s$ values for the array of POIs we are testing.\n",
    "6. Interpolate in order to find the value of the POI for which each of the above mentioned functions gets a value of 0.05 (i.e. the 95% CL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d075cf52-925e-49e0-bbb1-c2a2d2f1e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import expon\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from scipy import interpolate\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c89ac1-5b25-4e5a-affe-ad7044f2814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbounds = (0.1, 3.0)\n",
    "gmu = 1.2\n",
    "gsigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8f9735-d7d7-43ee-ad50-0bc9eb2ab71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood:\n",
    "    def __init__(self, function, data):\n",
    "        self.function = function\n",
    "        self.data = data\n",
    "\n",
    "    def __call__(self, params):\n",
    "        return np.prod(self.function(self.data, *params))\n",
    "\n",
    "\n",
    "class NLL(Likelihood):\n",
    "    def __call__(self, params):\n",
    "        return -np.sum([np.log(self.function(self.data, *params))])\n",
    "\n",
    "\n",
    "class BinnedLikelihood(Likelihood):\n",
    "    def __init__(self, function, hist, edges):\n",
    "        self.function = function\n",
    "        self.hist = hist\n",
    "        self.edges = edges\n",
    "\n",
    "    def __call__(self, params):\n",
    "        integration_limits = []\n",
    "        inf_limit = self.edges[0]\n",
    "        for sup_limit in self.edges[1:]:\n",
    "            integration_limits.append((inf_limit, sup_limit))\n",
    "            inf_limit = sup_limit\n",
    "        n_tot = self.hist.sum()\n",
    "        nu_is = np.array([n_tot * quad(lambda x: self.function(x, *params), inf_lim, sup_lim)[0] for inf_lim, sup_lim in integration_limits])\n",
    "        return - np.sum(self.hist * np.log(nu_is))\n",
    "\n",
    "    \n",
    "def model(x, f_sig, tau):\n",
    "    #return f_sig*(1/(gsigma * np.sqrt(2 * np.pi)) * np.exp(-(x - gmu)**2 / (2 * gsigma**2))) + (1-f_sig)*((1/tau) * np.exp(-(x / tau)))\n",
    "    return f_sig * norm(gmu, gsigma).pdf(x) + (1 - f_sig) * expon(scale=tau).pdf(x)\n",
    "\n",
    "    \n",
    "def q_mu(nll1, nll2, poi1, poi2):\n",
    "    q = 2 * (nll1 - nll2)\n",
    "    zeros = np.zeros(q.shape)\n",
    "    condition = (poi2 > poi1) | (q < 0)\n",
    "    return np.where(condition, zeros, q)\n",
    "\n",
    "\n",
    "def p_mu(q_mu, nsigma=0):\n",
    "    return 1 - norm.cdf(np.sqrt(q_mu) - nsigma)\n",
    "\n",
    "\n",
    "def p_alt(q_obs, q_alt):\n",
    "    sqrtqobs = np.sqrt(q_obs)\n",
    "    sqrtqalt = np.sqrt(q_alt)\n",
    "    return 1.0 - norm.cdf(sqrtqobs - sqrtqalt)\n",
    "\n",
    "\n",
    "def generate_asimov_hist(model, params, bounds, nbins=100):\n",
    "    bin_edges = np.linspace(bounds[0], bounds[1], nbins + 1)\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    integration_limits = []\n",
    "    inf_limit = bin_edges[0]\n",
    "    for sup_limit in bin_edges[1:]:\n",
    "        integration_limits.append((inf_limit, sup_limit))\n",
    "        inf_limit = sup_limit\n",
    "    hist = np.array([quad(lambda x: model(x, *params), inf_lim, sup_lim)[0] for inf_lim, sup_lim in integration_limits])\n",
    "\n",
    "    return hist, bin_edges, bin_centers\n",
    "\n",
    "\n",
    "def generate_pseudo_asimov_dataset(model, params, bounds, nevs=1000000, nbins=100):\n",
    "    hist, bin_edges, bin_centers = generate_asimov_hist(model, params, bounds, nbins)\n",
    "    edges_pairs = list(zip(bin_edges[:-1], bin_edges[1:]))\n",
    "    return np.concatenate([np.random.uniform(ep[0], ep[1], int(np.round(nevs*h))) for ep, h in zip(edges_pairs, hist)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab795591-88f9-43cb-9a3a-ad1c065b0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_and_model(ax, data, model, res, x_range, nbins=50):\n",
    "    ax.hist(data, bins=nbins, density=True, label=\"data\")\n",
    "    ax.plot(x_range, model(x_range, *res.x), 'r-', label=\"fit\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"f(x)\")\n",
    "    ax.set_xlim(0.1, 3.0)\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "def plot_all(ax, x, clsb, clb, cls, exp_cls, lk):\n",
    "    ax.fill_between(x, exp_cls[-2], exp_cls[2], color='y', label=\"$CL_s$ expected 68%\")\n",
    "    ax.fill_between(x, exp_cls[-1], exp_cls[1], color='g', label=\"$CL_s$ expected 95%\")\n",
    "    ax.plot(x, exp_cls[0], 'k--', label=\"$CL_s$ expected median\")\n",
    "    ax.plot(x, clsb, 'k-')\n",
    "    ax.plot(x, clsb, 'bo', label=\"$CL_{s+b}$\")\n",
    "    ax.plot(x, clb, 'k-')\n",
    "    ax.plot(x, clb, 'ko', label=\"$CL_b$\")\n",
    "    ax.plot(x, cls, 'k-')\n",
    "    ax.plot(x, cls, 'ro', label=\"$CL_s$\")\n",
    "    ax.hlines(y=0.05, xmin=x[0], xmax=x[-1], color='r', linestyle='-')\n",
    "    ax.set_ylabel(\"p-value\")\n",
    "    ax.set_xlabel(\"POI\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90833621-6990-48ee-bb14-ea1ca46cc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_compute_plot(n_sig, n_bkg, likelihood):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "    axes[0].clear()\n",
    "    axes[1].clear()\n",
    "    \n",
    "    bounds = (0.1, 3.0)\n",
    "    bnds  = ((0.001, 1.0), (0.03, 1.0)) #to feed the minimizer\n",
    "\n",
    "    # Generate dataset (with very small signal)\n",
    "    bkg = np.random.exponential(0.5, n_bkg)\n",
    "    peak = np.random.normal(gmu, gsigma, n_sig)\n",
    "    data = np.concatenate((bkg, peak))\n",
    "    data = data[(data > bounds[0]) & (data < bounds[1])]\n",
    "    if likelihood == \"binned\":\n",
    "        h, e = np.histogram(data, bins=100, range=bounds)\n",
    "        lk = BinnedLikelihood(model, h, e)\n",
    "    else:\n",
    "        lk = NLL(model, data)\n",
    "    x0 = [n_sig / (n_bkg + n_bkg), 0.5]\n",
    "    global_res = minimize(fun=lk, x0=x0, method='Powell', bounds=bnds, tol=1e-6)\n",
    "    axes[0] = plot_data_and_model(axes[0], data, model, global_res, np.linspace(bounds[0], bounds[1], 1000), 40)\n",
    "    \n",
    "    # compute observed quantities\n",
    "    pois_null = np.linspace(0.001, 0.2, 30)\n",
    "    pois_best = np.ones(pois_null.shape) * global_res.x[0]\n",
    "\n",
    "    nll_best = np.ones(pois_best.shape) * global_res.fun\n",
    "    nll_null = []\n",
    "    for pn in pois_null:\n",
    "        def to_minimize(params):\n",
    "            return lk([pn, *params])\n",
    "        x0 = global_res.x[1:] \n",
    "        res = minimize(fun=to_minimize, x0=x0, method='Powell', bounds=bnds, tol=1e-6)\n",
    "        nll_null.append(res.fun)\n",
    "\n",
    "    qobs = q_mu(nll_null, nll_best, pois_null, pois_best)\n",
    "    pobs = p_mu(qobs)\n",
    "\n",
    "    # Asimov\n",
    "    bkg_only_pars = [0.0] + list(global_res.x[1:])\n",
    "    if likelihood == \"binned\":\n",
    "        asimov_hist, asimov_edges, asimov_centers = generate_asimov_hist(model, bkg_only_pars, bounds, nbins=100)\n",
    "        asimov_hist *= (n_sig + n_bkg)\n",
    "        lk_asimov = BinnedLikelihood(model, asimov_hist, asimov_edges)\n",
    "    else:\n",
    "        asimov_dataset = generate_pseudo_asimov_dataset(model, bkg_only_pars, bounds, nevs=n_sig + n_bkg)\n",
    "        lk_asimov = NLL(model, asimov_dataset)\n",
    "        \n",
    "    def to_minimize(params):\n",
    "        return lk_asimov([0.0, *params])\n",
    "    x0 = global_res.x[1:]\n",
    "    global_res_asimov = minimize(fun=to_minimize, x0=x0, method='Powell', bounds=bnds[1:], tol=1e-6)\n",
    "\n",
    "    pois_alt = np.zeros(pois_null.shape)\n",
    "    nll_best_asimov = np.ones(pois_best.shape) * global_res_asimov.fun\n",
    "    nll_null_asimov = []\n",
    "    for pn in pois_null:\n",
    "        def to_minimize_loc(params):\n",
    "            return lk_asimov([pn, *params])\n",
    "        x0_loc = global_res_asimov.x\n",
    "        res = minimize(fun=to_minimize_loc, x0=x0_loc, method='Powell', bounds=bnds[1:], tol=1e-6)\n",
    "        nll_null_asimov.append(res.fun)\n",
    "    q_asimov = q_mu(nll_null_asimov, nll_best_asimov, pois_null, pois_alt)\n",
    "    p_asimov = p_alt(qobs, q_asimov)\n",
    "    cls = pobs / p_asimov\n",
    "\n",
    "    # Expected\n",
    "    exp_clsb = {}\n",
    "    exp_clb = {}\n",
    "    exp_cls = {}\n",
    "    sigmas = [0, 1, 2, -1, -2]\n",
    "    for sigma in sigmas:\n",
    "        exp_clsb[sigma] = p_mu(q_asimov, sigma)\n",
    "        exp_clb[sigma] = np.ones(exp_clsb[sigma].shape) * norm.cdf(sigma)\n",
    "        exp_cls[sigma] = exp_clsb[sigma] / exp_clb[sigma]\n",
    "    axes[1] = plot_all(axes[1], pois_null, pobs, p_asimov, cls, exp_cls, likelihood)\n",
    "\n",
    "    # Find upper limit\n",
    "    interpolated_funcs = {}\n",
    "    upper_limits = {}\n",
    "    interpolated_funcs[\"obs\"] = interpolate.interp1d(pois_null, cls, kind=\"cubic\")\n",
    "    for sigma in sigmas:\n",
    "        interpolated_funcs[\"exp_{}\".format(str(sigma).replace(\"-\", \"m\"))] = interpolate.interp1d(pois_null, exp_cls[sigma], kind=\"cubic\")\n",
    "    more_pois_null = np.linspace(0.001, 0.2, 10000)\n",
    "    line = np.ones(more_pois_null.shape) * 0.05\n",
    "    for name, func in interpolated_funcs.items():\n",
    "        interpolated_line = func(more_pois_null)\n",
    "        idx = np.argwhere(np.diff(np.sign(interpolated_line - line))).flatten()\n",
    "        upper_limits[name] = more_pois_null[idx]\n",
    "    print(\"upper_limits: \", json.dumps({k: list(l) for k, l in upper_limits.items()}, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8b67dc-576e-4016-986c-f4a6bda0cc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0cf6ccc54240aabb7a33b63cb3d384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='n_sig', max=50, min=1), IntSlider(value=300, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slider_plot = interactive(\n",
    "    generate_compute_plot, \n",
    "    n_sig=widgets.IntSlider(min=1, max=50, step=1, value=10),\n",
    "    n_bkg=widgets.IntSlider(min=250, max=500, step=1, value=300),\n",
    "    likelihood=widgets.SelectMultiple(options=[\"unbinned\", \"binned\"], value=(\"unbinned\", ))\n",
    "    )\n",
    "display(slider_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
